{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "udacity_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "cosOnlY5vkAE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "import helper\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_le6g-KJvl_0",
        "colab_type": "code",
        "outputId": "db2a5b21-e7b9-484d-b8d8-2d6852c18c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "cell_type": "code",
      "source": [
        "### Run this cell\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:06, 1452266.31it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 134296.81it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 1961673.92it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 49474.64it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "pqnurkMxvq9Y",
        "colab_type": "code",
        "outputId": "337e0317-78d8-4779-efac-43d319a8c371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yUjQanHrv_pU",
        "colab_type": "code",
        "outputId": "6a0cf814-9d4b-4c19-d6bf-eca4c6ddfb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSwAwICwBwICwBACD/wGtbSNaf/Jx7QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "qXUwsuQiwDD3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Solution\n",
        "def activation(x):\n",
        "    return 1/(1+torch.exp(-x))\n",
        "\n",
        "# Flatten the input images\n",
        "inputs = images.view(images.shape[0], -1)\n",
        "\n",
        "# Create parameters\n",
        "w1 = torch.randn(784, 256)\n",
        "b1 = torch.randn(256)\n",
        "\n",
        "w2 = torch.randn(256, 10)\n",
        "b2 = torch.randn(10)\n",
        "\n",
        "h = activation(torch.mm(inputs, w1) + b1)\n",
        "\n",
        "out = torch.mm(h, w2) + b2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-IKMfpxFxUSV",
        "colab_type": "code",
        "outputId": "794ed06d-8901-457b-e7e7-5690fcbde8ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(out.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lqZpSNTkya5I",
        "colab_type": "code",
        "outputId": "fe9ec3c9-7a4f-4ce1-e9be-ad32e20b9732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "## Solution\n",
        "def softmax(x):\n",
        "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
        "\n",
        "probabilities = softmax(out)\n",
        "\n",
        "# Does it have the right shape? Should be (64, 10)\n",
        "print(probabilities.shape)\n",
        "# Does it sum to 1?\n",
        "print(probabilities.sum(dim=1))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nMh_So2Cz7m5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lMxrpUe17k9H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "        \n",
        "        # Define sigmoid activation and softmax output \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Pass the input tensor through each of our operations\n",
        "        x = self.hidden(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.output(x)\n",
        "        x = self.softmax(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7upbM_Ue7qhX",
        "colab_type": "code",
        "outputId": "5b6e2ae0-ebf1-4412-b05b-c210dab1bce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "model = Network()\n",
        "model"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (softmax): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "7PFU79ir7t7I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Hidden layer with sigmoid activation\n",
        "        x = F.sigmoid(self.hidden(x))\n",
        "        # Output layer with softmax activation\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F8z7umGV71Dd",
        "colab_type": "code",
        "outputId": "0896a7f3-c1c5-4e08-fc10-35fc7a596386",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Defining the layers, 128, 64, 10 units each\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ''' Forward pass through the network, returns the output logits '''\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = Network()\n",
        "model"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Zhi6Tq2Q_wuX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training of neural network"
      ]
    },
    {
      "metadata": {
        "id": "2-HpaxTb8Zlf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E4JwKJ8y_3bW",
        "colab_type": "code",
        "outputId": "7b432a9f-599d-4124-cc90-7ca75a247947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3100, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E6kBKKHu_-kX",
        "colab_type": "code",
        "outputId": "f5c20e3c-dfaa-40b0-d845-4796602614c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our log-probabilities\n",
        "logps = model(images)\n",
        "# Calculate the loss with the logps and the labels\n",
        "loss = criterion(logps, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3157, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JcSzRtUnCkaC",
        "colab_type": "code",
        "outputId": "2d074873-649f-4711-c0d5-9b80361aa72f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "x = torch.randn(2,2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.0240,  0.5870],\n",
            "        [ 0.7938, -0.8080]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p5-BszIkwkxw",
        "colab_type": "code",
        "outputId": "86d50fa5-bb6e-4dcd-e304-46b3b67a0d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "y = x**2\n",
        "print(y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0485, 0.3446],\n",
            "        [0.6301, 0.6529]], grad_fn=<PowBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "603PNxsPxXT4",
        "colab_type": "code",
        "outputId": "a7b8b33e-c4b7-4509-b05c-9ecd5cf03f93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PowBackward0 object at 0x7f95db22bcf8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yyQjRd5Vxg-B",
        "colab_type": "code",
        "outputId": "72d02893-3cc1-437d-dd20-0afadd64914e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "z = y.mean()\n",
        "print(z)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6691, grad_fn=<MeanBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1T4gYRb9xlEP",
        "colab_type": "code",
        "outputId": "74185d9e-7fa4-4498-dd60-876e6dc3b1c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qeh51V6VxqCW",
        "colab_type": "code",
        "outputId": "38ed7ee9-23d3-44fd-a36e-8fc888df6ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "z.backward()\n",
        "print(x.grad)\n",
        "print(x/2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5120,  0.2935],\n",
            "        [ 0.3969, -0.4040]])\n",
            "tensor([[ 0.5120,  0.2935],\n",
            "        [ 0.3969, -0.4040]], grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HpkRjFhNyWqB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loss and Autograd together"
      ]
    },
    {
      "metadata": {
        "id": "Qt6Q1Ly_yDk8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images)\n",
        "loss = criterion(logps, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G3b-zqW1yhPt",
        "colab_type": "code",
        "outputId": "908d6579-f5c9-49ac-d90b-d427c1363bf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[-0.0013, -0.0013, -0.0013,  ..., -0.0013, -0.0013, -0.0013],\n",
            "        [ 0.0027,  0.0027,  0.0027,  ...,  0.0027,  0.0027,  0.0027],\n",
            "        [-0.0010, -0.0010, -0.0010,  ..., -0.0010, -0.0010, -0.0010],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0001, -0.0001, -0.0001,  ..., -0.0001, -0.0001, -0.0001],\n",
            "        [ 0.0022,  0.0022,  0.0022,  ...,  0.0022,  0.0022,  0.0022]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YEygFHXMz8dc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training network"
      ]
    },
    {
      "metadata": {
        "id": "ftIUcn_xyqJ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KCiyxCzO0AXr",
        "colab_type": "code",
        "outputId": "85c3c095-2a8f-477e-910d-e6c1d39af1a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[ 0.0192, -0.0249, -0.0184,  ..., -0.0345, -0.0354,  0.0171],\n",
            "        [-0.0057,  0.0031,  0.0026,  ..., -0.0011, -0.0334,  0.0278],\n",
            "        [-0.0007,  0.0211,  0.0017,  ...,  0.0286,  0.0296, -0.0222],\n",
            "        ...,\n",
            "        [ 0.0182,  0.0281,  0.0096,  ...,  0.0203,  0.0039, -0.0315],\n",
            "        [-0.0159,  0.0120, -0.0146,  ...,  0.0357, -0.0241,  0.0326],\n",
            "        [ 0.0318,  0.0016, -0.0329,  ...,  0.0088,  0.0222, -0.0080]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n",
            "        [ 0.0015,  0.0015,  0.0015,  ...,  0.0015,  0.0015,  0.0015],\n",
            "        [-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0008,  0.0008,  0.0008,  ...,  0.0008,  0.0008,  0.0008],\n",
            "        [-0.0024, -0.0024, -0.0024,  ..., -0.0024, -0.0024, -0.0024]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZkkMAgjd0y5c",
        "colab_type": "code",
        "outputId": "a2e51d16-f4c0-402f-c2a5-3bc9d3754d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "# Take an update step and few the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[ 0.0192, -0.0249, -0.0184,  ..., -0.0345, -0.0354,  0.0171],\n",
            "        [-0.0058,  0.0031,  0.0026,  ..., -0.0011, -0.0334,  0.0278],\n",
            "        [-0.0007,  0.0211,  0.0017,  ...,  0.0286,  0.0296, -0.0222],\n",
            "        ...,\n",
            "        [ 0.0182,  0.0281,  0.0096,  ...,  0.0203,  0.0039, -0.0315],\n",
            "        [-0.0159,  0.0120, -0.0146,  ...,  0.0357, -0.0241,  0.0326],\n",
            "        [ 0.0318,  0.0016, -0.0328,  ...,  0.0088,  0.0222, -0.0080]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WPNPWNiJ1Weq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training with multiple epochs"
      ]
    },
    {
      "metadata": {
        "id": "zK8IGcxM1AAI",
        "colab_type": "code",
        "outputId": "c4fb608d-6fd9-40bc-ec42-a809819654a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # TODO: Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.9268521932142375\n",
            "Training loss: 0.8704881996933077\n",
            "Training loss: 0.554302690634087\n",
            "Training loss: 0.447381482942145\n",
            "Training loss: 0.39660747652686734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OiLQ5nMK16-c",
        "colab_type": "code",
        "outputId": "f762dc81-9fec-438e-d1e0-4c7e047f477b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(images.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OKIZrNjXkIXZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def test_network(net, trainloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # Create Variables for the inputs and targets\n",
        "    inputs = Variable(images)\n",
        "    targets = Variable(images)\n",
        "\n",
        "    # Clear the gradients from all Variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass, then backward pass, then update weights\n",
        "    output = net.forward(inputs)\n",
        "    loss = criterion(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def view_recon(img, recon):\n",
        "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
        "        reconstruction also a PyTorch Tensor\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "    axes[0].imshow(img.numpy().squeeze())\n",
        "    axes[1].imshow(recon.data.numpy().squeeze())\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')\n",
        "\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZttHFvUn2KnT",
        "colab_type": "code",
        "outputId": "34812700-49c7-4fe5-8edd-99debfe3f061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = F.softmax(logps, dim=1)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADkCAYAAADNX7BjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "CNsrE_bv28hq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
